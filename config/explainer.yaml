# How many hops for the subgraph? (Only used if `user_batch_exp` == 1)
n_hops: 2
# `n_hops` is doubled such that each hop considers all the interactions of closest users in the bipartite graph
neighbors_hops: True
# optimizer for explainer
cf_optimizer: SGD
# learning rate of optimizer for explainer
cf_learning_rate: 3000 # 1200 for NDCGApprox

momentum: 0.0
# epochs to generate explanations
cf_epochs: 1000
# how many users should be considered to explain?
user_batch_exp: 64
# not consider the prediction loss
not_pred: True
# if the fair or pred loss should be deactivated if the top-k list is already perturbed
pred_same: False
# loss weight for the graph dist loss
cf_beta: 0.5
# the function used to check if the top-k list was perturbed
cf_dist: damerau_levenshtein
# how many top items to consider for model outcome list and fairness loss
cf_topk: 10

# loss weight for the fairness loss (used only if `explain_fairness` == True)
fair_beta: 0.5
dropout_prob: 0.3

edge_additions: False

# select which set need to be used to optimize the DP explainer. Choices ["train", "valid", "test"]
exp_rec_data: "test"

# device: cpu

# "local": the optimization uses the NDCG of the disadvantaged group computed locally for the current batch
# "global": the optimization uses the NDCG of the disadvantaged group computed globally on the original model
only_adv_group: "local"
# Choose if the edges of the advantaged group should be deleted or the opposite
delete_adv_group: True

# Last.FM 1K
# data_path: 'src/dataset/lastfm-1k' # for Last.FM 1K
# ML-1M
# data_path: 'dataset/ml-1m' # for ML-1M

# consider only the nodes at the last hop
sub_matrix_only_last_level: False
# does not consider the interactions of the user to explain, consider the remaining hops
not_user_sub_matrix: False
# does not perform perturbation, uses only the subgraph of the user to `explain` (used for analysis)
only_subgraph: False

# if to use fairness loss
explain_fairness: True
# sensitive attributes to be used in the fairness losses and for following analysis
sensitive_attribute: gender # age

# if True each new exp will have a different number of edges from the last one
save_unique_graph_dist_loss: True

# force return of explanations even though the top-k is not perturbed (only useful for hops analysis)
explainer_force_return: False

# ML-100K
load_col:
    inter: [user_id, item_id, timestamp]
    item: [item_id, class]
    user: [user_id, gender, age]

eval_args:
    split: {'LRS': None}
    order: RO  # not relevant
    group_by: '-'
    mode: 'full'

# Early stopping parameters
early_stopping:
    patience: 40  # a periodicity is visible on the charts, with low peaks better than the previous ones after 20-40 epochs
    ignore: 0
    method: 'consistency'
    mode: 'lt'  # lower than, use any other python func ('le', 'gt', 'ge')
    delta: 0.0015  # several experiments show many low peaks with differences about > 0.15, which are relevant for us
    pvalue:

previous_ndcg: False
previous_batch_LR_scaling: False

# Policies
explainer_policies:
    increase_disparity: True
    force_removed_edges: True
    group_deletion_constraint: False
